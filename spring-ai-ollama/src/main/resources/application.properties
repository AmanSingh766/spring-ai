spring.application.name=spring-ai-ollama
server.port=8081

# Ollama server URL
spring.ai.ollama.base-url=http://localhost:11434

# MAIN model (fast)
spring.ai.ollama.model=llama3.2:1b

# Chat options
spring.ai.ollama.chat.options.model=llama3.2:1b
spring.ai.ollama.chat.options.temperature=0.7

# Optional max tokens
# spring.ai.ollama.chat.options.max-tokens=2048
